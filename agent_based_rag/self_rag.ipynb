{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "LANGCHAIN_API_KEY=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look into the retriever grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..  \n",
    "If the document has words or meanings related to the question, mark it as relevant.  \n",
    "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\"\"\"\n",
    "    \n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..  \\nIf the document has words or meanings related to the question, mark it as relevant.  \\nGive a simple 'yes' or 'no' answer to show if the document is relevant or not.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, template='Retrieved document: \\n\\n {document} \\n\\n User question: {question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"what is ai agent?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Tool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Agent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Citation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_txt = docs[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"who is sunny svaita?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look into the data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Tool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Agent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:'),\n",
       " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Citation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"what is a AI agent?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='An AI agent is a system powered by a large language model (LLM) that can plan, reflect, remember, and use tools to accomplish tasks autonomously.  LLMs act as the brain of these agents, enabling them to understand and respond to complex instructions. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 1990, 'total_tokens': 2048, 'completion_time': 0.105454545, 'prompt_time': 0.063534477, 'queue_time': 0.025107962999999997, 'total_time': 0.168989022}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-77b1f029-1ccd-421f-997d-0c1ffb9bf348-0', usage_metadata={'input_tokens': 1990, 'output_tokens': 58, 'total_tokens': 2048})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system = \"\"\"You are a grader checking if an LLM generation is grounded in or supported by a set of retrieved facts.  \n",
    "Give a simple 'yes' or 'no' answer. 'Yes' means the generation is grounded in or supported by a set of retrieved the facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucinations_grader = hallucination_prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "print(hallucinations_grader.invoke({\"documents\": docs, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Answer Grader\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "print(answer_grader.invoke({\"question\": question, \"generation\": generation}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Re-writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a question re-writer that converts an input question into a better optimized version for vector store retrieval document.  \n",
    "You are given both a question and a document.  \n",
    "- First, check if the question is relevant to the document by identifying a connection or relevance between them.  \n",
    "- If there is a little relevancy, rewrite the question based on the semantic intent of the question and the context of the document.  \n",
    "- If no relevance is found, simply return this single word \"question not relevant.\" dont return the entire phrase \n",
    "Your goal is to ensure the rewritten question aligns well with the document for better retrieval.\"\"\"\n",
    "     \n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\"\"\"Here is the initial question: \\n\\n {question} \\n,\n",
    "             Here is the document: \\n\\n {documents} \\n ,\n",
    "             Formulate an improved question. if possible other return 'question not relevant'.\"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"who is a current indian prime minister?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question not relevant \\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_rewriter.invoke({\"question\":question,\"documents\":docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]\n",
    "    filter_documents: List[str]\n",
    "    unfilter_documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:AgentState):\n",
    "    print(\"----RETRIEVE----\")\n",
    "    question=state['question']\n",
    "    documents=retriever.get_relevant_documents(question)\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state:AgentState):\n",
    "    print(\"----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    filtered_docs = []\n",
    "    unfiltered_docs = []\n",
    "    for doc in documents:\n",
    "        score=my_retrieval_grader.invoke({\"question\":question, \"document\":doc})\n",
    "        grade=score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"----GRADE: DOCUMENT RELEVANT----\")\n",
    "            filtered_docs.append(doc)\n",
    "        else:\n",
    "            print(\"----GRADE: DOCUMENT NOT RELEVANT----\")\n",
    "            unfiltered_docs.append(doc)\n",
    "    if len(unfiltered_docs)>1:\n",
    "        return {\"unfilter_documents\": unfiltered_docs,\"filter_documents\":[], \"question\": question}\n",
    "    else:\n",
    "        return {\"filter_documents\": filtered_docs,\"unfilter_documents\":[],\"question\": question}\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state:AgentState):\n",
    "    print(\"----ACCESS GRADED DOCUMENTS----\")\n",
    "    state[\"question\"]\n",
    "    unfiltered_documents = state[\"unfilter_documents\"]\n",
    "    filtered_documents = state[\"filter_documents\"]\n",
    "    \n",
    "    \n",
    "    if unfiltered_documents:\n",
    "        print(\"----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\")\n",
    "        return \"transform_query\"\n",
    "    if filtered_documents:\n",
    "        print(\"----DECISION: GENERATE----\")\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:AgentState):\n",
    "    print(\"----GENERATE----\")\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    generation = rag_chain.invoke({\"context\": documents,\"question\":question})\n",
    "    return {\"documents\":documents,\"question\":question,\"generation\":generation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "def transform_query(state:AgentState):\n",
    "    question=state[\"question\"]\n",
    "    documents=state[\"documents\"]\n",
    "    \n",
    "    print(f\"this is my document{documents}\")\n",
    "    response = question_rewriter.invoke({\"question\":question,\"documents\":documents})\n",
    "    print(f\"----RESPONSE---- {response}\")\n",
    "    if response == 'question not relevant':\n",
    "        print(\"----QUESTION IS NOT AT ALL RELEVANT----\")\n",
    "        return {\"documents\":documents,\"question\":response,\"generation\":\"question was not at all relevant\"}\n",
    "    else:   \n",
    "        return {\"documents\":documents,\"question\":response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate_after_transformation(state:AgentState):\n",
    "    question=state[\"question\"]\n",
    "    \n",
    "    if question==\"question not relevant\":\n",
    "        return \"query_not_at_all_relevant\"\n",
    "    else:\n",
    "        return \"Retriever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "def grade_generation_vs_documents_and_question(state:AgentState):\n",
    "    print(\"---CHECK HELLUCINATIONS---\")\n",
    "    question= state['question']\n",
    "    documents = state['documents']\n",
    "    generation = state[\"generation\"]\n",
    "    \n",
    "    score = hallucinations_grader.invoke({\"documents\":documents,\"generation\":generation})\n",
    "    \n",
    "    grade = score.binary_score\n",
    "    \n",
    "    #Check hallucinations\n",
    "    if grade=='yes':\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        \n",
    "        print(\"---GRADE GENERATION vs QUESTION ---\")\n",
    "        \n",
    "        score = answer_grader.invoke({\"question\":question,\"generation\":generation})\n",
    "        \n",
    "        grade = score.binary_score\n",
    "        \n",
    "        if grade=='yes':\n",
    "            print(\"---DECISION: GENERATION ADDRESS THE QUESTION ---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
    "        \"not useful\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here the Langgraph workflow will start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f1bf259e10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Docs_Vector_Retrieve\", retrieve)\n",
    "workflow.add_node(\"Grading_Generated_Documents\", grade_documents) \n",
    "workflow.add_node(\"Content_Generator\", generate)\n",
    "workflow.add_node(\"Transform_User_Query\", transform_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1f1bf259e10>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START,\"Docs_Vector_Retrieve\")\n",
    "workflow.add_edge(\"Docs_Vector_Retrieve\",\"Grading_Generated_Documents\")\n",
    "workflow.add_conditional_edges(\"Grading_Generated_Documents\",\n",
    "                            decide_to_generate,\n",
    "                            {\n",
    "                            \"generate\": \"Content_Generator\",\n",
    "                            \"transform_query\": \"Transform_User_Query\"\n",
    "                            }\n",
    "                            )\n",
    "workflow.add_conditional_edges(\"Content_Generator\",\n",
    "                            grade_generation_vs_documents_and_question,\n",
    "                            {\n",
    "                            \"useful\": END,\n",
    "                            \"not useful\": \"Transform_User_Query\",\n",
    "                            }\n",
    "                            )\n",
    "workflow.add_conditional_edges(\"Transform_User_Query\",\n",
    "                decide_to_generate_after_transformation,\n",
    "                {\n",
    "                \"Retriever\":\"Docs_Vector_Retrieve\",\n",
    "                \"query_not_at_all_relevant\":END\n",
    "                }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "app=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display # type: ignore\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"Explain how the different types of agent memory work?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Short-term memory is similar to in-context learning, using the current input to make decisions. Long-term memory is external and stores a vast amount of information, often using a vector database for fast retrieval.  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 2081, 'total_tokens': 2128, 'completion_time': 0.085454545, 'prompt_time': 0.1067499, 'queue_time': 0.025613326000000006, 'total_time': 0.192204445}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8c3206a4-41ea-427c-84e4-66523ef0c38b-0', usage_metadata={'input_tokens': 2081, 'output_tokens': 47, 'total_tokens': 2128})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is a prompt engineering?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Prompt engineering is a method for communicating with large language models (LLMs) to guide their behavior and achieve desired outcomes. It involves crafting effective prompts that steer the LLM\\'s responses without altering its underlying weights.  Essentially, it\\'s about finding the right way to \"ask\" the LLM the right questions. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 1042, 'total_tokens': 1111, 'completion_time': 0.125454545, 'prompt_time': 0.043431389, 'queue_time': 0.023260444000000005, 'total_time': 0.168885934}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d66ad73c-25f9-471b-9269-2a797460baab-0', usage_metadata={'input_tokens': 1042, 'output_tokens': 69, 'total_tokens': 1111})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of data structure while creating ai agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"what is role of c language and php while creating ai agentic pattern?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1560\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1559\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1560\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   1561\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1562\u001b[0m     config,\n\u001b[0;32m   1563\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   1564\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   1565\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   1566\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   1567\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   1568\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1569\u001b[0m ):\n\u001b[0;32m   1570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1571\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1298\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1293\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m   1294\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[0;32m   1295\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[0;32m   1296\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1297\u001b[0m     ):\n\u001b[1;32m-> 1298\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1299\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1300\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1301\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1302\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1303\u001b[0m         ):\n\u001b[0;32m   1304\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1305\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\pregel\\runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\pregel\\retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\utils\\runnable.py:407\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\utils\\runnable.py:181\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 181\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\graph\\graph.py:93\u001b[0m, in \u001b[0;36mBranch._route\u001b[1;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m---> 93\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish(writer, \u001b[38;5;28minput\u001b[39m, result, config)\n",
      "File \u001b[1;32mc:\\Users\\sunny\\langgraph-end-to-end\\env\\lib\\site-packages\\langgraph\\utils\\runnable.py:173\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m    172\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m--> 173\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    175\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "Cell \u001b[1;32mIn[59], line 29\u001b[0m, in \u001b[0;36mgrade_generation_vs_documents_and_question\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot useful\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     \u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot useful\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"question\": \"who is a first president of USA?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"© 2024 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Because these documents are long, each document is split into paragraphs of 6 sentences, $\\\\{p\\\\}$. Paragraphs are ranked by TF-IDF based cosine similarity between evidence paragraphs and the query. Only the most relevant paragraph is used in the prompt to produce an answer $a$.')]\n",
      "----RESPONSE---- 'who is the first president of the united states?' \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"© 2024 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\"), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Because these documents are long, each document is split into paragraphs of 6 sentences, $\\\\{p\\\\}$. Paragraphs are ranked by TF-IDF based cosine similarity between evidence paragraphs and the query. Only the most relevant paragraph is used in the prompt to produce an answer $a$.')]\n",
      "----RESPONSE---- question not relevant \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Ye & Durrett (2022) found that the benefit of including explanations in the prompt is small to moderate for NLP tasks that involve reasoning over text (i.e. QA and NLI) and the effects vary by models. They observed that explanations are more likely to be nonfactual than be inconsistent (i.e. whether explanation entails prediction). Nonfactual explanations most likely lead to incorrect predictions.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='One observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='and $p_\\\\text{LM}(q \\\\mid p_i, a)$ are found to be most informative. $p_\\\\text{LM}(q \\\\mid p_i, a)$ captures how well the question can be explained by LM given evidence paragraph and answer and can reliably be used for reranking answer candidates.')]\n",
      "----RESPONSE---- question not relevant \n",
      "\n",
      "\n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Ye & Durrett (2022) found that the benefit of including explanations in the prompt is small to moderate for NLP tasks that involve reasoning over text (i.e. QA and NLI) and the effects vary by models. They observed that explanations are more likely to be nonfactual than be inconsistent (i.e. whether explanation entails prediction). Nonfactual explanations most likely lead to incorrect predictions.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='One observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='and $p_\\\\text{LM}(q \\\\mid p_i, a)$ are found to be most informative. $p_\\\\text{LM}(q \\\\mid p_i, a)$ captures how well the question can be explained by LM given evidence paragraph and answer and can reliably be used for reranking answer candidates.')]\n",
      "----RESPONSE---- question not relevant \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Ye & Durrett (2022) found that the benefit of including explanations in the prompt is small to moderate for NLP tasks that involve reasoning over text (i.e. QA and NLI) and the effects vary by models. They observed that explanations are more likely to be nonfactual than be inconsistent (i.e. whether explanation entails prediction). Nonfactual explanations most likely lead to incorrect predictions.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='One observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='and $p_\\\\text{LM}(q \\\\mid p_i, a)$ are found to be most informative. $p_\\\\text{LM}(q \\\\mid p_i, a)$ captures how well the question can be explained by LM given evidence paragraph and answer and can reliably be used for reranking answer candidates.')]\n",
      "----RESPONSE---- Please provide me with the question you'd like me to optimize.  \n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT NOT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\n",
      "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='For closed-book QA, each demonstration is formatted as follows to construct few-shot prompts. Swapping the question with the evidence (longer distance between questions and answers) is found to consistently yield lower results across all datasets.\\nEvidence: ...\\nQuestion: ...\\nAnswer: ...\\nThe answer probability is computed in three ways:'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='and $p_\\\\text{LM}(q \\\\mid p_i, a)$ are found to be most informative. $p_\\\\text{LM}(q \\\\mid p_i, a)$ captures how well the question can be explained by LM given evidence paragraph and answer and can reliably be used for reranking answer candidates.'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"}}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.')]\n",
      "----RESPONSE---- What are the key components of a LLM-powered autonomous agent system? \n",
      "\n",
      "\n",
      "\n",
      "----RETRIEVE----\n",
      "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----GRADE: DOCUMENT RELEVANT----\n",
      "----ACCESS GRADED DOCUMENTS----\n",
      "----DECISION: GENERATE----\n",
      "----GENERATE----\n",
      "---CHECK HELLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION ---\n",
      "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Key components of an LLM-powered autonomous agent system include planning (breaking down tasks and reflecting on past actions), memory (both short-term and long-term), and tool use (accessing external APIs for additional information and capabilities). \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 2023, 'total_tokens': 2075, 'completion_time': 0.094545455, 'prompt_time': 0.065010655, 'queue_time': 0.026483345000000005, 'total_time': 0.15955611}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-22199288-c4d8-4513-9424-63a721f5b904-0', usage_metadata={'input_tokens': 2023, 'output_tokens': 52, 'total_tokens': 2075})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.invoke(inputs)[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
